{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a709e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter\n",
    "import bz2\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e901c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(data_dir, output_file_path, can_reuse_output = True):\n",
    "    if os.path.isfile(output_file_path) and can_reuse_output:\n",
    "        return\n",
    "    \n",
    "    filenames = [filename for filename in os.listdir(data_dir) if filename.endswith('.json.bz2')]\n",
    "    input_files_paths = [os.path.join(data_dir, filename) for filename in filenames]\n",
    "\n",
    "    domain_matcher = re.compile(r\"^(?:https?:\\/\\/)?(?:[^@\\/\\n]+@)?(?:www\\.)?(?P<domain>[^:\\/?\\n]+)\")\n",
    "    get_domain_from_url = lambda string: domain_matcher.match(string).group('domain')\n",
    "        \n",
    "    with bz2.open(output_file_path, 'wb') as output_file:\n",
    "        for input_file_path in input_files_paths:\n",
    "            start = time.time()\n",
    "            \n",
    "            with bz2.open(input_file_path, 'rb') as input_file:\n",
    "                for i, line in enumerate(input_file):\n",
    "                    line = json.loads(line)\n",
    "                    \n",
    "                    data_line = {'quote_word_count': Counter(line['quotation']),\n",
    "                                 'speaker'         : line['speaker'],\n",
    "                                 'qids'            : line['qids'],\n",
    "                                 'first_date'      : line['date'],\n",
    "                                 'num_occurrences' : line['numOccurrences'],\n",
    "                                 'domains'         : [get_domain_from_url(url) for url in line['urls']]}\n",
    "\n",
    "                    output_file.write((json.dumps(data_line) + '\\n').encode('utf-8'))\n",
    "                    \n",
    "                    if not i % 1000000:\n",
    "                        print(\"Read\", i, \"lines from\", input_file_path, 'in', (time.time() - start) / 60, \"minutes\")\n",
    "                        \n",
    "            print(\"Finished reading\", input_file_path, 'in', (time.time() - start) / 60, \"minutes\")\n",
    "\n",
    "def load_col_from_json(input_file_path, columns):\n",
    "    \"\"\"\n",
    "    WARNING: DONT USE THIS UNLESS YOU WANT A BROKEN COMPUTER\n",
    "    \"\"\"\n",
    "    columns_dict = {key: [] for key in columns}\n",
    "    \n",
    "    with bz2.open(input_file_path, 'rb') as input_file:\n",
    "        start = time.time()\n",
    "        \n",
    "        for i, line in enumerate(input_file):\n",
    "            line = json.loads(line)\n",
    "            \n",
    "            for column in columns:\n",
    "                columns_dict[column].append(line[column])\n",
    "                \n",
    "            if not i % 1000000:\n",
    "                print(\"Read\", i, \"lines from\", input_file_path, 'in', (time.time() - start) / 60, \"minutes\")\n",
    "                \n",
    "    return pd.DataFrame(columns_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cffc7c5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'Data'\n",
    "CACHE_DIR = 'Cache'\n",
    "CACHE_FILE_PATH = os.path.join(CACHE_DIR, 'processed_data.json.bz2')\n",
    "\n",
    "process_files(DATA_DIR, CACHE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61e6189",
   "metadata": {},
   "source": [
    "# POUR KAOU\n",
    "\n",
    "Bonjour Kaou, tu as choisi word counting. Malheureusement je me suis rendu trop tard dans l'execution de la cellule précédente que j'avais oublié d'enlever les punctuation. Oups. Tu vas devoir itérer sur tous les clés du Compteur et enlever manuellement, et merge aussi les mêmes mots. Ou juste relancer la cellule du haut que j'ai déjà corrigé, mais que je n'ai pas eu le courage de relancer parce que ça prend beaucoup trop de temps (mais pas de resources, donc ne te fais pas de soucis tu peux le run sur n'importe quoi).\n",
    "\n",
    "Lis cette page pour des idées sur comment faire évoluer ton travail au délà du word counting: https://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "Je te mets aussi à disposition une simple fonction qui efface les \"English stop words\" d'une liste de mots. Par contre, fais gaffe à comment tu l'utilises. Les stop words ne sont pas nécéssairement toutes toujours inutiles. Lis sklearn pour les détails et affiche la liste avant d'utiliser la fonction pour voir si elle t'arrange. Tu peux covertir la fonction pour qu'elle droppe le compte des stop words dans un compteur en faisant del counter_object[word]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94165174",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12564/833452240.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mENGLISH_STOP_WORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mremove_punctuation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^a-z0-9 ]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "def remove_punctuation(string):\n",
    "    return re.sub(r'[^a-z0-9 ]', '', string)\n",
    "\n",
    "def remove_stopwords(word_list):\n",
    "    return [word for word in word_list if word not in ENGLISH_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290c689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc82165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c788fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3610133d",
   "metadata": {},
   "source": [
    "# POUR CÉLINA\n",
    "\n",
    "Coucou CC, il nous ont donné un file .parquet (juste un autre format de stockage binaire, un peux comme pickle) que normalement j'ai mis dans le dossier Data. Il devrait contenir plusieures informations sur chaque speaker. Tu peux le load comme ça, mais il me semble qu'il faut installer pyarrow (  conda install -c conda-forge pyarrow  ).\n",
    "\n",
    "Malheureusement il parait qu'ils aient utilisé le QID de Wikidata pour encoder la profession, religion et tout le reste. Probablement une des première choses à faire est de trouver un moyen de mapper les QIDS à des string, que je sais faire en faisant des queries à wikidata mais je me demande s'il n'y a pas un moyen plus simple. Au pire on le fait (que une fois de toute façon).\n",
    "\n",
    "Il faudrait aussi s'assurer que dans le parquet qu'ils nous donnent il n'y ait pas que peu d'occupations au bol, mais un grand nombre comme celui qu'on voit sur wikidata, car autrement on a le même problème que quand je faisais les queries (que j'ai découvert comment resudre) qui est que pour des gens avec beaucoup de professions on en avait seulement 3 au bol.\n",
    "\n",
    "Oubliepas que je t'ai dit qu'il y a un problème avec l'antivirus et la lecture de .json. Je ne sais pas pourquoi, mais à chaque fois que tu veux commencer à lire un json tu dois mettre en standby l'anti-virus pendant une minute. C'est assez chiant, mais je n'ai pas trouvé d'autre solution (sinon, le programme ne plante pas, il s'arrete juste et ne dit rien et attend jusqu'à que tu desactives).\n",
    "\n",
    "Pour le moment c'est tout je crois."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95724d7",
   "metadata": {},
   "source": [
    "- Cas quand plusieurs qids par quote, lequel on prend ? (je sais pas s'il y a moyen de savoir laquelle est la plus populaire, peut-être celle qui a le plus de liens externes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "960f4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d397305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@utils.cache_to_file_pickle(\"function-groupby_speaker\", cache_dir = CACHE_DIR)\n",
    "def groupby_speaker(input_file_path):\n",
    "    speakers_dict = {}\n",
    "    \n",
    "    with bz2.open(input_file_path, 'rb') as input_file:\n",
    "        start = time.time()\n",
    "        \n",
    "        for i, line in enumerate(input_file):\n",
    "            line = json.loads(line)\n",
    "            \n",
    "            if not line['qids']:\n",
    "                continue\n",
    "            \n",
    "            qids = tuple(line['qids']) if len(line['qids']) > 1 else line['qids'][0]\n",
    "            \n",
    "            # if multiple qids given for one quote, take the first one for now\n",
    "            if qids in speakers_dict:\n",
    "                speakers_dict[qids]['quote_count'] += 1\n",
    "                speakers_dict[qids]['speaker']     |= set([line['speaker']])\n",
    "                # speakers_dict[qids]['num_occurrences'].append(line['numOccurrences'])\n",
    "                \n",
    "                speakers_dict[qids]['num_occurrences'].append(len(line['domains']))\n",
    "                \n",
    "            else:\n",
    "                speakers_dict[qids] = {'quote_count': 1, \\\n",
    "                                       'speaker': set([line['speaker']]),\n",
    "                                       'num_occurrences': [len(line['domains'])]}\n",
    "                                       # 'num_occurrences': [line['numOccurrences']]}\n",
    "                \n",
    "                \n",
    "            if not i % 1000000:\n",
    "                print(\"Read\", i, \"lines from\", input_file_path, 'in', (time.time() - start) / 60, \"minutes\")\n",
    "            if i == 1000000:\n",
    "                break\n",
    "    return speakers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8648a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 0 lines from Cache\\processed_data.json.bz2 in 0.00019950469334920247 minutes\n",
      "Read 1000000 lines from Cache\\processed_data.json.bz2 in 0.37840535640716555 minutes\n"
     ]
    }
   ],
   "source": [
    "data_quotes = groupby_speaker(input_file_path = CACHE_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28b65431",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quotes_df = pd.DataFrame(data_quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f00ddd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote_count</th>\n",
       "      <th>speaker</th>\n",
       "      <th>num_occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q270316</th>\n",
       "      <td>30</td>\n",
       "      <td>{Jeanne Shaheen}</td>\n",
       "      <td>[2, 2, 1, 2, 1, 1, 2, 2, 3, 2, 1, 1, 1, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1253</th>\n",
       "      <td>339</td>\n",
       "      <td>{Ban Ki Moon, Ban Ki-Moon, Ban Ki-moon, Ban ki...</td>\n",
       "      <td>[2, 1, 99, 1, 2, 1, 2, 91, 7, 1, 3, 2, 12, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q468374</th>\n",
       "      <td>5</td>\n",
       "      <td>{Sri Sri Ravi Shankar}</td>\n",
       "      <td>[1, 5, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q19874690</th>\n",
       "      <td>5</td>\n",
       "      <td>{Jamal Rifi}</td>\n",
       "      <td>[1, 1, 1, 8, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q18601741</th>\n",
       "      <td>1</td>\n",
       "      <td>{Richard Burmeister}</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5271548</th>\n",
       "      <td>9</td>\n",
       "      <td>{Diane Ravitch}</td>\n",
       "      <td>[1, 1, 3, 1, 1, 2, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Q15735939, Q25189328, Q5107375, Q5110828, Q5112832, Q948687)</th>\n",
       "      <td>55</td>\n",
       "      <td>{Chris Matthews}</td>\n",
       "      <td>[1, 1, 3, 1, 3, 1, 2, 2, 1, 1, 1, 1, 2, 1, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q51797519</th>\n",
       "      <td>5</td>\n",
       "      <td>{Steven Stack}</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2287947</th>\n",
       "      <td>292</td>\n",
       "      <td>{JORDAN Spieth, Jordan Spieth}</td>\n",
       "      <td>[1, 6, 13, 9, 1, 1, 1, 1, 1, 47, 14, 1, 1, 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Q2376327, Q313381, Q7815037)</th>\n",
       "      <td>368</td>\n",
       "      <td>{TOM BRADY, Tom Brady}</td>\n",
       "      <td>[1, 1, 1, 1, 7, 5, 1, 2, 1, 10, 1, 2, 2, 1, 4,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   quote_count  \\\n",
       "Q270316                                                     30   \n",
       "Q1253                                                      339   \n",
       "Q468374                                                      5   \n",
       "Q19874690                                                    5   \n",
       "Q18601741                                                    1   \n",
       "Q5271548                                                     9   \n",
       "(Q15735939, Q25189328, Q5107375, Q5110828, Q511...          55   \n",
       "Q51797519                                                    5   \n",
       "Q2287947                                                   292   \n",
       "(Q2376327, Q313381, Q7815037)                              368   \n",
       "\n",
       "                                                                                              speaker  \\\n",
       "Q270316                                                                              {Jeanne Shaheen}   \n",
       "Q1253                                               {Ban Ki Moon, Ban Ki-Moon, Ban Ki-moon, Ban ki...   \n",
       "Q468374                                                                        {Sri Sri Ravi Shankar}   \n",
       "Q19874690                                                                                {Jamal Rifi}   \n",
       "Q18601741                                                                        {Richard Burmeister}   \n",
       "Q5271548                                                                              {Diane Ravitch}   \n",
       "(Q15735939, Q25189328, Q5107375, Q5110828, Q511...                                   {Chris Matthews}   \n",
       "Q51797519                                                                              {Steven Stack}   \n",
       "Q2287947                                                               {JORDAN Spieth, Jordan Spieth}   \n",
       "(Q2376327, Q313381, Q7815037)                                                  {TOM BRADY, Tom Brady}   \n",
       "\n",
       "                                                                                      num_occurrences  \n",
       "Q270316                                             [2, 2, 1, 2, 1, 1, 2, 2, 3, 2, 1, 1, 1, 1, 2, ...  \n",
       "Q1253                                               [2, 1, 99, 1, 2, 1, 2, 91, 7, 1, 3, 2, 12, 1, ...  \n",
       "Q468374                                                                               [1, 5, 1, 1, 1]  \n",
       "Q19874690                                                                             [1, 1, 1, 8, 2]  \n",
       "Q18601741                                                                                         [1]  \n",
       "Q5271548                                                                  [1, 1, 3, 1, 1, 2, 1, 1, 1]  \n",
       "(Q15735939, Q25189328, Q5107375, Q5110828, Q511...  [1, 1, 3, 1, 3, 1, 2, 2, 1, 1, 1, 1, 2, 1, 3, ...  \n",
       "Q51797519                                                                             [1, 1, 1, 1, 1]  \n",
       "Q2287947                                            [1, 6, 13, 9, 1, 1, 1, 1, 1, 47, 14, 1, 1, 10,...  \n",
       "(Q2376327, Q313381, Q7815037)                       [1, 1, 1, 1, 7, 5, 1, 2, 1, 10, 1, 2, 2, 1, 4,...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_quotes_df.T.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9019af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data = pd.read_parquet('Data/speaker_attributes.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c23656c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_data.id.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6627eb4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aliases</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>lastrevid</th>\n",
       "      <th>ethnic_group</th>\n",
       "      <th>US_congress_bio_ID</th>\n",
       "      <th>occupation</th>\n",
       "      <th>party</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>candidacy</th>\n",
       "      <th>type</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7078648</th>\n",
       "      <td>[Christopher Douglas Matthews]</td>\n",
       "      <td>[+1989-10-06T00:00:00Z]</td>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>1317867389</td>\n",
       "      <td>[Q49085]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Q19204627, Q19841381]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Q15735939</td>\n",
       "      <td>Chris Matthews</td>\n",
       "      <td>None</td>\n",
       "      <td>item</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                aliases            date_of_birth nationality  \\\n",
       "7078648  [Christopher Douglas Matthews]  [+1989-10-06T00:00:00Z]       [Q30]   \n",
       "\n",
       "             gender   lastrevid ethnic_group US_congress_bio_ID  \\\n",
       "7078648  [Q6581097]  1317867389     [Q49085]               None   \n",
       "\n",
       "                     occupation party academic_degree         id  \\\n",
       "7078648  [Q19204627, Q19841381]  None            None  Q15735939   \n",
       "\n",
       "                  label candidacy  type religion  \n",
       "7078648  Chris Matthews      None  item     None  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_data.loc[speaker_data[\"id\"] == 'Q15735939']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2818791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f86fda96",
   "metadata": {},
   "source": [
    "# POUR ANDREA\n",
    "Bonjour Andrea, ça va? Oui très bien, merci. J'essaye de poser une base pour commencer le Milestone 2 du projet. Et toi? Moi aussi, drôle ça. Bon, à toute. Bon travail, à toute.\n",
    "\n",
    "Il faut rerun la lecture du dataset avec la remotion de ponctuation.\n",
    "\n",
    "Je suppose que tu vas faire la partie de correler les dates à des événements, et si t'as envie d'essayer d'extraire la variance. Par contre pour le moment je ne sais pas trop comment ça colle avec le reste de l'analyse. Dans le sens que la data story va parler de quoi concernant les dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92973258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851cc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9d6612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00c7d9d3",
   "metadata": {},
   "source": [
    "# POUR MATTIA\n",
    "Buongiorno Mattia, je suppose que tu vas faire la partie de regarder les newspapers et correler avec les speakers et, si on arrive, l'argument de la quote. Pour toi je crois que juste load le processed_data.json.bz2 et garder que les clés 'domains' et 'speaker' devrait le faire. Il faudra sûrement se coordonner avec Célina et Kaou pour voir justement comment correler les trucs. Pour le moment, je t'avoue que comme pour ma partie, je n'ai pas une idéé précide de comment ceci va coller dans une data story coherente. Faudra que Kaou et Célina avancent rapidement pour que tu puisse commencer à repliquer leur travail mais pour différents newspapers. Ou je ne sais pas. Faudra juste pas qu'on reste bloqués si on attend quelqu'un d'autre."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
